# micrograd

small and simple scalar optimization inspired by pytorch and karpathy. \
It creates a dynamic computation graph that can be used to calculate derivatives
and use simple SGD to update parameters. \
can optimize functions with +,-,*,/. 
